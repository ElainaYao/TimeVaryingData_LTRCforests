E = E[,c(1,5:13)]
E = cbind(KM,E)
E = E[rowSums(E==Inf)==0,]
E = E[rowSums(E==0)==0,]
########## ======== presented way 1 ========= #######
boxplot.matrix(E, main=c(type,distname[dd],modelname[mm],ndataname[nn]),
xaxt="n",
ylim = aa,
ylab = "Integrated L2")
abline(h=median(E[,1]),lty = 2, col = 2, lwd = 4)
abline(v=5.5,lty = 2, col = 4, lwd = 4)
abline(v=8.5,lty = 2, col = 4, lwd = 4)
xtick <- c(1:11)
text(x=xtick,  par("usr")[3],
labels = c("KM",names(resall$L2)[c(1,5:13)]),
pos = 1, xpd = TRUE, cex = 1.4)
}
}
dev.off()
}
pdf_file_name <- sprintf("/Users/wyao/Dropbox/RESEARCH/time-varyingRSF/report12_Denis/codes/Check_cplthist/data-out/sqrt/plot_RC_compare_Sqrt_Fraction/%1.0fvar_N%1.0f_%s_npseu%1.0f_c%1.0f.pdf",
varN,N,ddist[dd],nnpseu[pp],ccrate[cc])
pdf(pdf_file_name, width=15, height = 20)
par(mfrow=c(3,2))
for (dd in 3){
for (mm in 2:4){
for (type in c("PH","nonPH")){
aa = NULL
filename <- sprintf('/Users/wyao/Dropbox/RESEARCH/time-varyingRSF/report12_Denis/codes/Check_cplthist/data-out/sqrt/L2indep_%s_%1.0fvar_N%1.0f_%s_m%1.0f_c%1.0f_p%1.0f.rds',
type,varN,N,ddist[dd],mmodel[mm],ccrate[cc],nnpseu[pp])
resall <- readRDS(filename)
KM = matrix(unlist(resall$L2KM),ncol = 1, byrow = FALSE)
E = matrix(unlist(resall$L2), ncol = 13, byrow = FALSE)
E = E[,c(1,5:13)]
E = cbind(KM,E)
E = E[rowSums(E==Inf)==0,]
E = E[rowSums(E==0)==0,]
########## ======== presented way 1 ========= #######
boxplot.matrix(E, main=c(type,distname[dd],modelname[mm],ndataname[nn]),
xaxt="n",
ylim = aa,
ylab = "Integrated L2")
abline(h=median(E[,1]),lty = 2, col = 2, lwd = 4)
abline(v=2.5,lty = 2, col = 4, lwd = 4)
abline(v=5.5,lty = 2, col = 4, lwd = 4)
abline(v=8.5,lty = 2, col = 4, lwd = 4)
xtick <- c(1:11)
text(x=xtick,  par("usr")[3],
labels = c("KM",names(resall$L2)[c(1,5:13)]),
pos = 1, xpd = TRUE, cex = 1.4)
}
}
dev.off()
}
sqrt(1000)
traforest_wy
itct_term_WI
print(itct_term_WI)
setwd("/Users/wyao/Dropbox/RESEARCH/time-varyingRSF/wy_code/afterDenis")
source("Timevarying_nonlinear_gnrt_0707_partial.R")
source("Timevarying_itct_gnrt_0707_partial.R")
source("Timevarying_linear_gnrt_0707_partial.R")
source("../LTRCIF.R")
source("../tuneLTRCIF_ltrc.R")
source("../tuneLTRCTSF_ltrc.R")
source("../LTRCrsfP.R")
source("../predict_LTRCrsfP_ltrc.R")
source("Surv_funct.R") # to use getSurv
source("grouping.R")
library(ipred)
library(partykit)
library(survival)
library(LTRCtrees)
library(prodlim)
library(truncdist)
library(isotone)
library(scclust)
ll = 1
set.seed(101)
sampleID = sample(10000000,500)
set.seed(sampleID[ll])
model
Distribution
censor.rate
num.pseu
num.pseu = 11
N = 10
if (model == 2){
RET <- Timevarying_linear_gnrt(N=N, Distribution=Distribution, censor.rate=censor.rate, npseu = num.pseu, partial = TRUE)
rtype = "linear"
} else if (model == 3) {
RET <- Timevarying_nonlinear_gnrt(N=N, Distribution=Distribution, censor.rate=censor.rate, npseu = num.pseu, partial = TRUE)
rtype = "nonlinear"
} else if (model == 1) {
RET <- Timevarying_tree_gnrt(N=N, Distribution=Distribution, censor.rate=censor.rate, npseu = num.pseu, partial = TRUE)
rtype = "tree"
} else if (model == 4) {
RET <- Timevarying_itct_gnrt(N=N, Distribution=Distribution, censor.rate=censor.rate, npseu = num.pseu)
rtype = "interaction"
} else {
stop("Wrong model type is used.")
}
if (type == "complete"){
DATA <- RET$fullData
DATA = DATA[,c("I","ID","X1","X2","X3","X4","X5","X6","X7","X8","X9","X10",
"X11","X12","X13","X14","X15","X16","X17","X18","X19","X20","Start","Stop","Event","Xi","Model","Dist")]
} else if (type == "baseline"){
DATA <- RET$baselineData
DATA = DATA[,c("I","ID","X1","X2","X3","X4","X5","X6","X7","X8","X9","X10",
"X11","X12","X13","X14","X15","X16","X17","X18","X19","X20","Start","Stop","Event","Xi","Model","Dist")]
} else if (type == "partial"){
DATA <- RET$partialData
DATA = DATA[,c("I","ID","X1","X2","X3","X4","X5","X6","X7","X8","X9","X10",
"X11","X12","X13","X14","X15","X16","X17","X18","X19","X20","Start","Stop","Event","Xi","Model","Dist")]
} else {
stop("Wrong type is given.")
}
type
type = "complete"
if (type == "complete"){
DATA <- RET$fullData
DATA = DATA[,c("I","ID","X1","X2","X3","X4","X5","X6","X7","X8","X9","X10",
"X11","X12","X13","X14","X15","X16","X17","X18","X19","X20","Start","Stop","Event","Xi","Model","Dist")]
} else if (type == "baseline"){
DATA <- RET$baselineData
DATA = DATA[,c("I","ID","X1","X2","X3","X4","X5","X6","X7","X8","X9","X10",
"X11","X12","X13","X14","X15","X16","X17","X18","X19","X20","Start","Stop","Event","Xi","Model","Dist")]
} else if (type == "partial"){
DATA <- RET$partialData
DATA = DATA[,c("I","ID","X1","X2","X3","X4","X5","X6","X7","X8","X9","X10",
"X11","X12","X13","X14","X15","X16","X17","X18","X19","X20","Start","Stop","Event","Xi","Model","Dist")]
} else {
stop("Wrong type is given.")
}
Info = NULL
Info$Coeff <- RET$Coeff
Info$Rtype <- rtype
Info$Dist <- Distribution
Info$Set <- "PH"
#### Time points to be evaluated
Tpnt = c(0,sort(unique(DATA$Stop)))
Tpnt
print(DATA[DATA$ID==1,c("I","ID","X1","X2","X3","X4","X5","X6","Start","Stop","Event")])
print(DATA[DATA$ID==11,c("I","ID","X1","X2","X3","X4","X5","X6","Start","Stop","Event")])
###################### ---------------- noise variables ----------------- ###############################
if (varN == 20){
Formula = Surv(Start,Stop,Event) ~ X1+X2+X3+X4+X5+X6+X7+X8+X9+X10+X11+X12+X13+X14+X15+X16+X17+X18+X19+X20
Formula_TD = Surv(Start,Stop,Event, type = "counting") ~ X1+X2+X3+X4+X5+X6+X7+X8+X9+X10+X11+X12+X13+X14+X15+X16+X17+X18+X19+X20
} else {
Formula = Surv(Start,Stop,Event) ~ X1+X2+X3+X4+X5+X6+X7+X8+X9+X10+X11+X12+X13+X14+X15+X16+X17+X18+X19+X20+
X21+X22+X23+X24+X25+X26+X27+X28+X29+X30+X31+X32+X33+X34+X35+X36+X37+X38+X39+X40+
X41+X42+X43+X44+X45+X46+X47+X48+X49+X50+X51+X52+X53+X54+X55+X56+X57+X58+X59+X60+
X61+X62+X63+X64+X65+X66+X67+X68+X69+X60+X71+X72+X73+X74+X75+X76+X77+X78+X79+X80
Formula_TD = Surv(Start,Stop,Event, type = "counting") ~ X1+X2+X3+X4+X5+X6+X7+X8+X9+X10+X11+X12+X13+X14+X15+X16+X17+X18+X19+X20+
X21+X22+X23+X24+X25+X26+X27+X28+X29+X30+X31+X32+X33+X34+X35+X36+X37+X38+X39+X40+
X41+X42+X43+X44+X45+X46+X47+X48+X49+X50+X51+X52+X53+X54+X55+X56+X57+X58+X59+X60+
X61+X62+X63+X64+X65+X66+X67+X68+X69+X60+X71+X72+X73+X74+X75+X76+X77+X78+X79+X80
}
Formula_TD0 = Surv(Start,Stop,Event, type = "counting") ~ 1
ntree = 100L
M = varN
rm(RET)
gc()
print("Dataset has been created ...")
# Construct distance metric
my_dist <- distances(DATA,
#id_variable = "ID",
dist_variables = c("X1","X2","X3","X4","X5","X6","X7","X8","X9","X10",
"X11","X12","X13","X14","X15","X16","X17","X18","X19","X20"))
my_dist
# Make clustering with at least 30 data points in each cluster
clusterID <- sc_clustering(my_dist, size_constraint = 30)
clusterID
IDfold = createKFoldCV(Kfold=Nfold, N=nrow(DATA))
IDfold
# number of clusters
J = length(unique(clusterID))
# number of folds
K = length(IDfold)
# time points to evaluate
Tpnt = c(0, sort(unique(DATA$Stop)))
lenT = length(Tpnt)
groupEp_temp <- matrix(0,nrow = J,ncol = lenT)
groupEn_temp <- matrix(0,nrow = J,ncol = lenT)
method_all = c("Cox","cfD","cfT","rsfD","rsfT","tsfD","tsfT")
Formula = Surv(Start,Stop,Event) ~ X1+X2+X3+X4+X5+X6+X7+X8+X9+X10+X11+X12+X13+X14+X15+X16+X17+X18+X19+X20
## Last update on Mar 19th: can deal with right-censored
## == also the proposed rule has all been changed
## Last update on Feb 25th: can change Control for mtry != NULL
###################################################################################
## fill NA with the nearest values
library(zoo)
# Check na.locf(x,fromLast = FALSE) and na.locf(x,fromLast = TRUE)
# to replace NA by the nearest non_NA value (zoo)
###################################################################################
traforest_wy <- function(formula, data, ntree, mtry=NULL, log_first = TRUE, Control = NULL,
sampletype = "sub", stepFactor = 2, trace = FALSE){
formula0 = formula
formula0[[3]] = 1
if (is.null(mtry)){
TSFfsub1 <- tuneLTRCTSF_ltrc(formula = formula, data = data, ntreeTry = ntree, control = Control,
sampleType = sampletype, log_first = log_first,
stepFactor = stepFactor, trace = trace, doBest = TRUE)
} else {
if (is.null(Control)){
Control = partykit::ctree_control(teststat = "quad", testtype = "Univ",
mincriterion = 0, saveinfo = FALSE,
minsplit = 20,
minbucket = 7,
minprob = 0.01)
}
rex <- Coxph(formula = formula0, data = data, log_first = log_first)
if (sampletype == "sub"){
id_uniq <- unique(data$ID)
n_uniq <- length(id_uniq)
size = floor(n_uniq * 0.632)
wt <- matrix(0, nrow = nrow(data), ncol = ntree)
weights <- sapply(1:ntree, function(itree){
wt = rep(0,nrow(data))
idx <- sample(id_uniq, size = size, replace = FALSE)
for (ii in 1:size) {
inidx <- which(data$ID == idx[ii])
wt[inidx] = 1
}
return(wt)
})
TSFfsub1 <- traforest(rex, formula = formula, data = data, ntree = ntree,
weights = weights, mtry = mtry,
control = Control)
} else {
TSFfsub1 <- traforest(rex, formula = formula, data = data, ntree = ntree, mtry = mtry,
control = Control)
}
}
TSFfsub1
}
###################################################################################
predict_LTRCtrafo_ltrc <- function(object, newdata, ensemble = TRUE){
nIDxdata <- predict(object, newdata = object$data, type = "node") # of size Ndata*ntree
nIDxnewdata <- predict(object, newdata = newdata, type = "node") # of size Newdata*ntree
if (ensemble) {
ntree = length(object$weights)
weights <- object$weights
pred = lapply(1:nrow(newdata), function(newdata_i){
same_nd <- rep(0,nrow(object$data))
for (b in 1:ntree){
## ID of observations in the b-th bootstrap samples
rw = which(weights[[b]]==1)
## ID of observations that will fall in the same terminal node as the new observation in b-th tree
tw <- which(nIDxdata[[b]] == nIDxnewdata[[b]][newdata_i])
tw <- tw[tw%in%rw]
same_nd[tw] <- same_nd[tw]+1
}
same_nd = same_nd/sum(same_nd)
if (ncol(as.matrix(object$data[,1])) == 2){
survival::survfit(Surv(time,status)~1, data = data.frame(as.matrix(object$data[,1])),
weights = same_nd)
}else {
survival::survfit(Surv(start,stop,status)~1, data = data.frame(as.matrix(object$data[,1])),
weights = same_nd)
}
})
} else {
pred = lapply(1:nrow(newdata), function(newdata_i){
same_nd <- rep(0,nrow(object$data))
same_nd[nIDxdata == nIDxnewdata[newdata_i]] = 1
same_nd = same_nd/sum(same_nd)
if (ncol(as.matrix(object$data[,1])) == 2){
survival::survfit(Surv(time,status)~1, data = data.frame(as.matrix(object$data[,1])),
weights = same_nd)
}else {
survival::survfit(Surv(start,stop,status)~1, data = data.frame(as.matrix(object$data[,1])),
weights = same_nd)
}
})
}
return(pred)
}
###################################################################################
## to create K-fold CV dataset
createKFoldCV <- function(Kfold, N){
N_shuffled = sample(N, N)
dataCV = split(N_shuffled, sort(N_shuffled %% Kfold)+1)
return(dataCV)
}
## Grouping idea in Mathlouthi et al 2019
grouping <- function(Data, cluster_id, id_fold, method = c("Cox","cfD","rsfD","tsfD","cfT","rsfT","tsfT"),
Formula, ntree){
# number of the variables
allX <- substring(Formula,1)[[3]]
nameX <- strsplit(gsub("\\+", '', allX)," ")[[1]]
nameX <- nameX[nameX!=""]
nvar = length(nchar(nameX))
# number of clusters
J = length(unique(cluster_id))
# number of folds
K = length(id_fold)
# time points to evaluate
Tpnt = c(0, sort(unique(Data$Stop)))
lenT = length(Tpnt)
groupEp_temp <- matrix(0,nrow = J,ncol = lenT)
groupEn_temp <- matrix(0,nrow = J,ncol = lenT)
for (kk in 1:K){
pt0 = proc.time()
trainDATA = Data[-id_fold[[kk]],]
testDATA = Data[id_fold[[kk]],]
#print(trainDATA[1,])
## +1: to match tLR column index
groupkk = cluster_id[id_fold[[kk]]]+1
## index in the testDATA for members in each group
idx_groupkk = split(seq_along(groupkk), groupkk)
if (method == "Cox"){
################ ================================ Cox model ============================ ########################
#### Training
Coxfit <- coxph(formula = Formula, data = trainDATA)
#### Prediction
predCox <- survfit(Coxfit, newdata = testDATA)
rm(Coxfit)
predSP = sapply(1:nrow(testDATA), function(j_i){
Shat_final = rep(0, lenT)
idx = which(findInterval(Tpnt,testDATA[j_i,c("Start","Stop")],
rightmost.closed = TRUE)==1L)
TTpnt = Tpnt[idx]
Shat_final[idx] = getSurv(predCox[j_i], TTpnt)
return(Shat_final)
})
rm(predCox)
gc()
} else if (method == "rsfD"){
################ ==================== RSF with default parameter settings ============== ########################
randomSurvFP <- LTRCrsfP(formula = Formula, data = trainDATA, ntree = ntree,
nodesize = 15, mtry = ceiling(sqrt(nvar)),
bootstraptype = "seu", samptype = "swor")
predSP <- predict_LTRCrsfP_ltrc(randomSurvFP, testDATA, tpnt=Tpnt)
rm(randomSurvFP)
gc()
} else if (method == "cfD"){
################ ==================== CF with default parameter settings ============== ########################
Cfsub <- LTRCIF(formula = Formula, data = trainDATA, sampletype = "seu",
mtry = ceiling(sqrt(nvar)), ntree = ntree,
control = partykit::ctree_control(teststat = "quad", testtype = "Univ",
minsplit = 20L,
minbucket = 7L,
minprob = 0.01,
mincriterion = 0, saveinfo = FALSE))
predcfOOB <- predict(object = Cfsub, newdata = testDATA, type = "prob")
rm(Cfsub)
predSP = sapply(1:nrow(testDATA), function(j_i){
Shat_final = rep(0, lenT)
idx = which(findInterval(Tpnt,testDATA[j_i,c("Start","Stop")],
rightmost.closed = TRUE)==1L)
TTpnt = Tpnt[idx]
Shat_final[idx] = getSurv(predcfOOB[[j_i]], TTpnt)
return(Shat_final)
})
rm(predcfOOB)
gc()
} else if (method == "tsfD"){
################ ==================== TSF with default parameter settings ============== ########################
TSFsub <- traforest_wy(formula = Formula, data = trainDATA, mtry = ceiling(sqrt(nvar)),
ntree = ntree, sampletype = "seu")
predtsfOOB <- predict_LTRCtrafo_ltrc(object = TSFsub, newdata = testDATA)
rm(TSFsub)
predSP = sapply(1:nrow(testDATA), function(j_i){
Shat_final = rep(0, lenT)
idx = which(findInterval(Tpnt,testDATA[j_i,c("Start","Stop")],
rightmost.closed = TRUE)==1L)
TTpnt = Tpnt[idx]
Shat_final[idx] = getSurv(predtsfOOB[[j_i]], TTpnt)
return(Shat_final)
})
rm(predtsfOOB)
gc()
} else if (method == "cfT"){
################ ==================== CF with proposed parameter settings ============== ########################
Cfsub <- tuneLTRCIF_ltrc(formula = Formula, data = trainDATA, sampleType = "seu", stepFactor = 2,
control = partykit::ctree_control(teststat = "quad", testtype = "Univ",
minsplit = max(ceiling(sqrt(nrow(trainDATA))),20),
minbucket = max(ceiling(sqrt(nrow(trainDATA))),7),
minprob = 0.01,
mincriterion = 0, saveinfo = FALSE),
ntreeTry = ntree, trace=FALSE, doBest = TRUE)
predcfOOB <- predict(object = Cfsub, newdata = testDATA, type = "prob")
rm(Cfsub)
predSP = sapply(1:nrow(testDATA), function(j_i){
Shat_final = rep(0, lenT)
idx = which(findInterval(Tpnt,testDATA[j_i,c("Start","Stop")],
rightmost.closed = TRUE)==1L)
TTpnt = Tpnt[idx]
Shat_final[idx] = getSurv(predcfOOB[[j_i]], TTpnt)
return(Shat_final)
})
rm(predcfOOB)
gc()
} else if (method == "rsfT"){
################ ==================== RSF with proposed parameter settings ============== ########################
mtryT <- tune(formula = Formula, data = trainDATA, nodesizeTry = max(ceiling(sqrt(nrow(trainDATA))),15),
ntreeTry = 100, samptype = "swor", bootstraptype = "seu", stepFactor = 2,
trace = FALSE, doBest = FALSE)$optimal[2]
randomSurvFP <- LTRCrsfP(formula = Formula, data = trainDATA, ntree = ntree,
nodesize = max(ceiling(sqrt(nrow(trainDATA))),15),
mtry = mtryT, bootstraptype = "seu", samptype = "swor")
predSP <- predict_LTRCrsfP_ltrc(randomSurvFP, testDATA, tpnt=Tpnt)
rm(randomSurvFP)
gc()
} else if (method == "tsfT"){
################ ==================== TSF with proposed parameter settings ============== ########################
TSFsub <- traforest_wy(formula = Formula_TD, data = trainDATA,
Control = partykit::ctree_control(teststat = "quad", testtype = "Univ",
minsplit = max(ceiling(sqrt(nrow(trainDATA))),20),
minbucket = max(ceiling(sqrt(nrow(trainDATA))),7),
minprob = 0.01,
mincriterion = 0, saveinfo = FALSE),
ntree = ntree, sampletype = "seu", trace = FALSE)
predtsfOOB = predict_LTRCtrafo_ltrc(object=TSFsub, newdata=testDATA)
rm(TSFsub)
predSP = sapply(1:nrow(testDATA), function(j_i){
Shat_final = rep(0, lenT)
idx = which(findInterval(Tpnt,testDATA[j_i,c("Start","Stop")],
rightmost.closed = TRUE)==1L)
TTpnt = Tpnt[idx]
Shat_final[idx] = getSurv(predtsfOOB[[j_i]], TTpnt)
return(Shat_final)
})
rm(predtsfOOB)
gc()
}
if (length(idx_groupkk) == J){
## When all groups have more than one observation
for (j in 1:J){
x = as.matrix(predSP[,idx_groupkk[[j]]]) ## survival prob for j-th group among all unique groupID that testDATA contains
groupEp_temp[j,] = groupEp_temp[j,] + rowSums(x)
groupEn_temp[j,] = groupEn_temp[j,] + rowSums(x!=0) ## how many non-zero survival prob at each time
}
} else {
## can just use this one, but just slower
idx_a = as.numeric(names(idx_groupkk))
for (j in 1:length(idx_a)){
x = as.matrix(predSP[,idx_groupkk[[j]]])
groupEp_temp[idx_a[j],] = groupEp_temp[idx_a[j],] + rowSums(x)
groupEn_temp[idx_a[j],] = groupEn_temp[idx_a[j],] + rowSums(x!=0) ## how many non-zero survival prob at each time
}
}
pt1 <- proc.time() - pt0
print(sprintf("%s -- Round %1.0f takes around %1.0f minutes",method,kk,round(pt1[3]/60)))
}
Vj <- sapply(1:J, function(j) {
V_j = rep(0,2)
pb_j = groupEp_temp[j,]/groupEn_temp[j,]
cutaway0 = is.nan(pb_j)
cutaway = (cutaway0[1:(lenT-1)] + cutaway0[2:lenT] !=0)
## to get the group estimate
groupIDj = which(cluster_id==(j-1))
groupKMj = survfit(Surv(Start,Stop,Event)~1, data=Data[groupIDj,])
pb_j_True = getSurv(groupKMj,Tpnt)
# pb_j_True[is.nan(pb_j)] = 0
f_itg = (pb_j - pb_j_True)^2
v_t = f_itg[-length(f_itg)] + f_itg[-1]
v_t[cutaway] = 0
V_j[1] = diff(Tpnt)%*%(v_t)/2
pb_j[cutaway0]=NA
pb_j_fillna = na.approx(pb_j) # start from the first non NA, and end with the last nonNA
lenNA = length(pb_j_fillna)
idxNAL = which(cutaway0==0)[1]
idxNAR = idxNAL + lenNA - 1
pb_j_gpava = 1-gpava(Tpnt[idxNAL:idxNAR], 1-pb_j_fillna, solver = weighted.mean)$x
f_itg = (pb_j_gpava - pb_j_True[idxNAL:idxNAR])^2
v_t = f_itg[-length(f_itg)] + f_itg[-1]
v_t[cutaway[idxNAL:(idxNAR-1)]] = 0
V_j[2] = diff(Tpnt[idxNAL:idxNAR])%*%(v_t)/2
return(V_j)
})
V = rowMeans(Vj)
V
}
m_i=4
grouping(Data = DATA, cluster_id = clusterID, id_fold = IDfold, method = method_all[m_i],
Formula = Formula, ntree = ntree)
m_i=6
grouping(Data = DATA, cluster_id = clusterID, id_fold = IDfold, method = method_all[m_i],
Formula = Formula, ntree = ntree)
setwd("/Users/wyao/Dropbox/RESEARCH/time-varyingRSF/wy_code/randomForestSRC")
# create_package("rpart")
# clone the source code from the package repo, add your modifications, load the package with
# devtools::load_all() (must be inside the package folder) and test it
devtools::load_all()
setwd("/Users/wyao/Dropbox/RESEARCH/time-varyingRSF/transformation/mlt_changed")
# clone the source code from the package repo, add your modifications, load the package with
# devtools::load_all() (must be inside the package folder) and test it
devtools::load_all()
setwd("/Users/wyao/Dropbox/RESEARCH/time-varyingRSF/transformation/mlt_changed")
# clone the source code from the package repo, add your modifications, load the package with
# devtools::load_all() (must be inside the package folder) and test it
devtools::load_all()
setwd("/Users/wyao/Dropbox/RESEARCH/time-varyingRSF/transformation/tram_changed")
# clone the source code from the package repo, add your modifications, load the package with
# devtools::load_all() (must be inside the package folder) and test it
devtools::load_all()
setwd("/Users/wyao/Dropbox/RESEARCH/time-varyingRSF/transformation/trtf_changed")
# create_package("rpart")
# clone the source code from the package repo, add your modifications, load the package with
# devtools::load_all() (must be inside the package folder) and test it
devtools::load_all()
grouping(Data = DATA, cluster_id = clusterID, id_fold = IDfold, method = method_all[m_i],
Formula = Formula, ntree = ntree)
## Last update on Mar 19th: can deal with right-censored
## == also the proposed rule has all been changed
## Last update on Feb 25th: can change Control for mtry != NULL
###################################################################################
## fill NA with the nearest values
library(zoo)
na.approx(c(NA,NA,1,1))
